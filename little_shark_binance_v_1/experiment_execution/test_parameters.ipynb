{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Intervals, trainning_periods, z-score_windows and see the win-rate, average returns, trading time for the first trading oppotunities in the next 50 intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set config\n",
    "SET_INTERVALS = [\"1m\", \"3m\", \"5m\", \"15m\", \"30m\", \"1h\", \"2h\"]\n",
    "SET_INTERVALS_INT_MINS = [1, 3, 5, 15, 30, 60, 120]\n",
    "SET_TRAINNING_PERIODS = [100, 150, 200, 250, 300, 350, 400, 450, 500, 550, 600, 650, 700, 750, 800, 850, 900]\n",
    "SET_Z_SCORE_WINDOW = [20, 40, 60, 80, 100, 120, 140, 160, 180, 200, 220, 240, 260]\n",
    "SET_TRIGGER_Z_SCORE_THRESHOD = [0.4, 0.8, 1.2, 1.6, 2.0, 2.4, 2.8]\n",
    "TRADING_TIMES_THRESHOD = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get tradeable symbols in tradeable_symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from binance.um_futures import UMFutures\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "session_public = UMFutures()\n",
    "ONBOARD_TIME_THRESHOD = datetime.datetime(2023, 1, 6)\n",
    "TRADING_VOLUME_THRESHOD_RATE = 1 / 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def binance_get_24h_trading_volume_usdt(symbol: str) -> float:\n",
    "    \"\"\"get the 24h trading volume in usdt\n",
    "\n",
    "    Args:\n",
    "        symbol (str): symbol name\n",
    "\n",
    "    Returns:\n",
    "        float: the trading volume in usdt\n",
    "    \"\"\"\n",
    "    return float(session_public.ticker_24hr_price_change(symbol)[\"quoteVolume\"])\n",
    "\n",
    "\n",
    "def binance_get_exchange_symbols():\n",
    "    \"\"\"get the exchange symbols from the binance\n",
    "\n",
    "    Returns:\n",
    "        _type_: a dict with all the symbols information in it\n",
    "    \n",
    "    See: https://binance-docs.github.io/apidocs/futures/en/#exchange-information\n",
    "    \"\"\"\n",
    "    return session_public.exchange_info()[\"symbols\"]\n",
    "\n",
    "def transform_timestamp_to_datetime(timestamp: int):\n",
    "    return datetime.datetime.fromtimestamp(int(timestamp)/1000)\n",
    "\n",
    "def get_tradeable_symbols_dynamic() -> list:\n",
    "    \"\"\"Get tradeable symbols from the Binance, and return the list of \n",
    "    symbols and the number of tradeable pairs\n",
    "    \n",
    "    Only trade on USDT\n",
    "    Only trade the coins that are on board for a certain time period\n",
    "\n",
    "    Args:\n",
    "       None\n",
    "\n",
    "    Returns:\n",
    "        sym_list(list): the list contains all the tradeable symbols\n",
    "        count(int): the size of the list\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    sym_list = []\n",
    "    BTCUSDT_trading_volume = binance_get_24h_trading_volume_usdt(\"BTCUSDT\")\n",
    "    \n",
    "    symbols = binance_get_exchange_symbols()\n",
    "    for symbol in symbols:\n",
    "        if (symbol[\"quoteAsset\"] == \"USDT\" and symbol[\"status\"]==\"TRADING\"\n",
    "            and transform_timestamp_to_datetime(symbol[\"onboardDate\"]) <= ONBOARD_TIME_THRESHOD # coins onboard should not be later than this time\n",
    "            and binance_get_24h_trading_volume_usdt(symbol[\"symbol\"]) >= TRADING_VOLUME_THRESHOD_RATE * BTCUSDT_trading_volume): # trading volume\n",
    "            \n",
    "            sym_list.append(symbol[\"symbol\"])\n",
    "            count += 1\n",
    "            time.sleep(0.1)\n",
    "    print(f\"{count} pairs found\")\n",
    "\n",
    "    # return all the tradeable symbol and the size of the list\n",
    "    return sym_list\n",
    "\n",
    "tradeable_symbols = get_tradeable_symbols_dynamic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tradeable_symbols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store the price of different Intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "def binance_get_recent_close_price(symbol: str, interval: str, limit: int) ->list:\n",
    "    \"\"\"get the recent close price list from binace with the related interval\n",
    "\n",
    "    Args:\n",
    "        symbol (_type_): the name of the symbol\n",
    "\n",
    "    Returns:\n",
    "        _type_: list\n",
    "    \"\"\"\n",
    "    price_list = []\n",
    "    prices = session_public.klines(symbol=symbol, interval=interval,limit = limit)\n",
    "    for price in prices:\n",
    "        price_list.append(float(price[4])) # change str to float\n",
    "    if len(price_list) == limit:\n",
    "        return price_list\n",
    "    else: return\n",
    "\n",
    "# Store price histry for all available pairs\n",
    "def store_price_history_static(symbols: list, interval) -> str:\n",
    "    \"\"\"\n",
    "    Store the price history for the given symbols and return the filename of the stored data.\n",
    "\n",
    "    Args:\n",
    "        symbols (list): List of symbols for which price history needs to be stored.\n",
    "\n",
    "    Returns:\n",
    "        str: Filename of the stored data.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get prices and store in DataFrame\n",
    "    counts = 0\n",
    "    price_history_dict = {}\n",
    "    for sym in symbols:\n",
    "        price_history = binance_get_recent_close_price(sym, interval=interval, limit=1500)\n",
    "        if len(price_history) == 1500: # make sure that each symbol has the same amount of data\n",
    "            price_history_dict[sym] = price_history\n",
    "            counts += 1\n",
    "    print(f\"{counts} items stored, {len(symbols)-counts}items not stored\")\n",
    "    \n",
    "    # Output prices to JSON\n",
    "    if len(price_history_dict) > 0:\n",
    "        filename = f\"{interval}_price_list.json\"\n",
    "        with open(filename, \"w\") as fp:\n",
    "            json.dump(price_history_dict, fp, indent=4)\n",
    "        print(\"Prices saved successfully.\")\n",
    "    time.sleep(5)\n",
    "\n",
    "# for interval in SET_INTERVALS:\n",
    "for interval in SET_INTERVALS:\n",
    "    store_price_history_static(tradeable_symbols, interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get cointegrated pairs and store in csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "INVESTIBLE_CAPITAL_EACH_TIME = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binance_get_latest_price(symbol: str) -> float:\n",
    "    \"\"\"\n",
    "    Retrieves the latest price for a given symbol from the Binance API.\n",
    "\n",
    "    Args:\n",
    "        symbol (str): The symbol for which to retrieve the latest price.\n",
    "\n",
    "    Returns:\n",
    "        float: The latest price for the specified symbol.\n",
    "    \"\"\"\n",
    "    return float(session_public.ticker_price(symbol)[\"price\"])\n",
    "\n",
    "def get_trade_qty_each_time(symbol_1: str, symbol_2: str, hedge_ratio):\n",
    "    estimated_trade_qty_symbol_1 = INVESTIBLE_CAPITAL_EACH_TIME / (binance_get_latest_price(symbol_1) + hedge_ratio * binance_get_latest_price(symbol_2))\n",
    "    estimated_trade_qty_symbol_2 = (estimated_trade_qty_symbol_1 * hedge_ratio)\n",
    "    \n",
    "    return estimated_trade_qty_symbol_1, estimated_trade_qty_symbol_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import coint\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def calculate_cointegration_static(series_1, series_2):\n",
    "    \"\"\"\n",
    "    Calculate the cointegration between two series and return cointegration flag,\n",
    "    hedge ratio, and initial intercept.\n",
    "\n",
    "    Args:\n",
    "        series_1 (array like): First series for cointegration analysis.\n",
    "        series_2 (array like): Second series for cointegration analysis.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing cointegration flag, hedge ratio, and initial intercept.\n",
    "\n",
    "    Notes:\n",
    "        - The series should have the same length.\n",
    "        - Cointegration tests the long-term relationship between two time series.\n",
    "        - The cointegration flag indicates if the two series are cointegrated.\n",
    "        - The hedge ratio represents the relationship between the two series.\n",
    "        - The initial intercept is the intercept of the linear regression model.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the input series have different lengths.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    coint_flag = 0\n",
    "    coint_res = coint(series_1, series_2)\n",
    "    coint_t = coint_res[0]\n",
    "    p_value = coint_res[1]\n",
    "    critical_value = coint_res[2][1]\n",
    "    \n",
    "    \n",
    "    # get initial intercept and hedge_ration of the model\n",
    "    series_2 = sm.add_constant(series_2)\n",
    "    model = sm.OLS(series_1, series_2).fit()\n",
    "    initial_intercept = model.params[0]\n",
    "    hedge_ratio = model.params[1]\n",
    "\n",
    "    if (p_value < 0.03) and (coint_t < critical_value):\n",
    "        coint_flag = 1\n",
    "    return coint_flag, p_value, hedge_ratio, initial_intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.regression.rolling import RollingOLS\n",
    "# series_2 = [1,2,3,4,5,6,7,8,9]\n",
    "# series_1 = [1,3,5,7,9,11,13,15,17]\n",
    "\n",
    "def calculate_spread_hedge_ratio_window(series_1: list, series_2: list, window: int):\n",
    "    \"\"\"\n",
    "    Calculates the spread between two series using a given hedge ratio.\n",
    "\n",
    "    Args:\n",
    "        series_1 (list): A list of values representing the first series.\n",
    "        series_2 (list): A list of values representing the second series.\n",
    "        hedge_ratio (float): The hedge ratio to be applied.\n",
    "\n",
    "    Returns:\n",
    "        list: A list containing the calculated spread.\n",
    "    \"\"\"\n",
    "    data_series_1 = pd.DataFrame(series_1)\n",
    "    data_series_2 = pd.DataFrame(series_2)\n",
    "    \n",
    "    endog = data_series_1\n",
    "    exog = sm.add_constant(data_series_2)\n",
    "    rols = RollingOLS(endog, exog, window=window)\n",
    "    rres = rols.fit()\n",
    "    params = rres.params.replace(np.nan, 0)\n",
    "    hedge_ratio = params.iloc[:, 1].tolist()\n",
    "    \n",
    "    spread = pd.Series(series_1) - (pd.Series(series_2) * hedge_ratio)\n",
    "    spread[:window-1] = 0\n",
    "    return spread.tolist(), hedge_ratio\n",
    "\n",
    "# spread, hedge_ratio = calculate_spread_hedge_ratio_window(series_1, series_2, 3)\n",
    "# spread, hedge_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRADING_FEE_RATE = 0.0004\n",
    "def calculate_z_score_window(spread: list, window: int) -> list:\n",
    "    \"\"\"\n",
    "    Calculates the Z-Score of a given spread.\n",
    "\n",
    "    Args:\n",
    "        spread (list): A list of values representing the spread.\n",
    "\n",
    "    Returns:\n",
    "        list: A list containing the Z-Score values.\n",
    "    \"\"\"\n",
    "    data = pd.DataFrame(spread)\n",
    "    rolling = data.rolling(window=window)\n",
    "    m = rolling.mean()\n",
    "    s = rolling.std()\n",
    "    z_score = (data - m) / s\n",
    "    \n",
    "    # assign the first num of window z-score to be 0\n",
    "    z_score[0][:(window-1)] = 0\n",
    "\n",
    "    return z_score[0].tolist()\n",
    "\n",
    "\n",
    "\n",
    "def calculate_std_spread(spread: list):\n",
    "    \"\"\"\n",
    "    Calculates the std of a given spread.\n",
    "\n",
    "    Args:\n",
    "        spread (list): A list of values representing the spread.\n",
    "\n",
    "    Returns:\n",
    "        std: float\n",
    "    \"\"\"\n",
    "    data = pd.DataFrame(spread)\n",
    "    return data.std().values[0]\n",
    "\n",
    "def check_differnet_signal(a,b):\n",
    "    return abs(a + b) != abs(a) + abs(b)\n",
    "\n",
    "def get_backtesting_properties(series_1: list, series_2: list, hedge_ratio_list: float, zscore_series: list, TRIGGER_Z_SCORE_THRESHOD: float):\n",
    "    trade_oppotunities = 0\n",
    "    last_value = 0.00\n",
    "    enter_market_signal = False\n",
    "    \n",
    "    cumulative_return = 0\n",
    "    cumulative_trading_qty = 0\n",
    "    count_entering_time = 0\n",
    "    \n",
    "    open_long_price_list = []\n",
    "    open_short_price_list = []\n",
    "    \n",
    "    win_times = 0\n",
    "    peak_loss = 0\n",
    "    \n",
    "    \n",
    "    for index, value in enumerate(zscore_series):\n",
    "        if abs(value) >= abs(TRIGGER_Z_SCORE_THRESHOD) and not check_differnet_signal(value, last_value):\n",
    "            \n",
    "            enter_market_signal = True\n",
    "            \n",
    "            if value >= TRIGGER_Z_SCORE_THRESHOD:\n",
    "                direction = \"sell\"\n",
    "            elif value <= -TRIGGER_Z_SCORE_THRESHOD:\n",
    "                direction = \"buy\"\n",
    "            \n",
    "            if count_entering_time < TRADING_TIMES_THRESHOD:\n",
    "                cumulative_trading_qty += (INVESTIBLE_CAPITAL_EACH_TIME / (series_1[index] + hedge_ratio_list[index] * series_2[index]))  # qty for each symbol\n",
    "                if direction == \"buy\":\n",
    "                    open_long_price_list.append(series_1[index])\n",
    "                    open_short_price_list.append(series_2[index])\n",
    "                elif direction == \"sell\":\n",
    "                    open_short_price_list.append(series_1[index])\n",
    "                    open_long_price_list.append(series_2[index])\n",
    "                    \n",
    "                count_entering_time += 1\n",
    "\n",
    "        # Calculate the peak loss during the trade\n",
    "        if enter_market_signal:\n",
    "            if direction == \"buy\":\n",
    "                long_profit = (series_1[index] - sum(open_long_price_list)/len(open_long_price_list)) * cumulative_trading_qty\n",
    "                short_profit = (sum(open_short_price_list)/len(open_short_price_list) - series_2[index]) * cumulative_trading_qty * hedge_ratio_list[index]\n",
    "            elif direction == \"sell\":\n",
    "                long_profit = (series_2[index] - sum(open_long_price_list)/len(open_long_price_list)) * cumulative_trading_qty * hedge_ratio_list[index]\n",
    "                short_profit = (sum(open_short_price_list)/len(open_short_price_list) - series_1[index]) * cumulative_trading_qty\n",
    "            current_revenue = long_profit + short_profit\n",
    "            peak_loss = min(peak_loss, current_revenue)\n",
    "        \n",
    "        # Calculate the returns when exiting the market\n",
    "        if enter_market_signal and check_differnet_signal(value, last_value):\n",
    "            trade_oppotunities += 1\n",
    "            exiting_profit = current_revenue - INVESTIBLE_CAPITAL_EACH_TIME * count_entering_time * TRADING_FEE_RATE # revenue for all symbols\n",
    "            \n",
    "            # calculate the win rate\n",
    "            if exiting_profit > 0:\n",
    "                win_times += 1\n",
    "\n",
    "            # Cumulate the return\n",
    "            cumulative_return += exiting_profit\n",
    "            \n",
    "            # Reset\n",
    "            enter_market_signal = False\n",
    "            cumulative_trading_qty = 0\n",
    "            count_entering_time = 0\n",
    "            direction = \"\"\n",
    "            open_long_price_list = []\n",
    "            open_short_price_list = []\n",
    "        \n",
    "        last_value = value\n",
    "    \n",
    "    if trade_oppotunities > 0:\n",
    "        win_rate = win_times / trade_oppotunities\n",
    "    else:\n",
    "        win_rate = 0\n",
    "    \n",
    "    # Calculate the recent trade qty\n",
    "    recent_trade_qty = (INVESTIBLE_CAPITAL_EACH_TIME / (series_1[-1] + hedge_ratio_list[-1] * series_2[-1]))\n",
    "    \n",
    "    return trade_oppotunities, cumulative_return, win_rate, recent_trade_qty, peak_loss\n",
    "\n",
    "def calculate_pairs_trading_result(series_1, series_2, num_window: int, z_score_threshod: float) -> tuple:\n",
    "    \n",
    "    spread, hedge_ratio_list = calculate_spread_hedge_ratio_window(series_1, series_2, window=num_window)\n",
    "    zscore_series = calculate_z_score_window(spread, window=num_window)\n",
    "    std = calculate_std_spread(spread)\n",
    "    \n",
    "    # Get recent z score\n",
    "    recent_z_score = zscore_series[-1]\n",
    "    \n",
    "    trade_oppotunities, cumulative_return, win_rate, recent_trade_qty, peak_loss = get_backtesting_properties(series_1, series_2, hedge_ratio_list, zscore_series, z_score_threshod)\n",
    "        \n",
    "    return trade_oppotunities, cumulative_return, win_rate, recent_trade_qty, recent_z_score, peak_loss, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pairs_one_time_trading_result(series_1_real_test, series_2_real_test, z_score_window, z_score_threshod):\n",
    "    spread, hedge_ratio_list = calculate_spread_hedge_ratio_window(series_1_real_test, series_2_real_test, window=z_score_window)\n",
    "    zscore_series = calculate_z_score_window(spread, window=z_score_window)\n",
    "    \n",
    "    trade_oppotunities = 0\n",
    "    last_value = 0.00\n",
    "    enter_market_signal = False\n",
    "    \n",
    "    cumulative_return = 0\n",
    "    cumulative_trading_qty = 0\n",
    "    count_entering_time = 0\n",
    "    \n",
    "    open_long_price_list = []\n",
    "    open_short_price_list = []\n",
    "    \n",
    "    peak_loss = 0\n",
    "    \n",
    "    \n",
    "    for index, value in enumerate(zscore_series):\n",
    "        if abs(value) >= abs(z_score_threshod) and not check_differnet_signal(value, last_value):\n",
    "            \n",
    "            enter_market_signal = True\n",
    "            \n",
    "            if value >= z_score_threshod:\n",
    "                direction = \"sell\"\n",
    "            elif value <= -z_score_threshod:\n",
    "                direction = \"buy\"\n",
    "            \n",
    "            if count_entering_time < TRADING_TIMES_THRESHOD:\n",
    "                cumulative_trading_qty += (INVESTIBLE_CAPITAL_EACH_TIME / (series_1_real_test[index] + hedge_ratio_list[index] * series_2_real_test[index]))  # qty for each symbol\n",
    "                if direction == \"buy\":\n",
    "                    open_long_price_list.append(series_1_real_test[index])\n",
    "                    open_short_price_list.append(series_2_real_test[index])\n",
    "                elif direction == \"sell\":\n",
    "                    open_short_price_list.append(series_1_real_test[index])\n",
    "                    open_long_price_list.append(series_2_real_test[index])\n",
    "                    \n",
    "                count_entering_time += 1\n",
    "\n",
    "        # Calculate the peak loss during the trade\n",
    "        if enter_market_signal:\n",
    "            if direction == \"buy\":\n",
    "                long_profit = (series_1_real_test[index] - sum(open_long_price_list)/len(open_long_price_list)) * cumulative_trading_qty\n",
    "                short_profit = (sum(open_short_price_list)/len(open_short_price_list) - series_2_real_test[index]) * cumulative_trading_qty * hedge_ratio_list[index]\n",
    "            elif direction == \"sell\":\n",
    "                long_profit = (series_2_real_test[index] - sum(open_long_price_list)/len(open_long_price_list)) * cumulative_trading_qty * hedge_ratio_list[index]\n",
    "                short_profit = (sum(open_short_price_list)/len(open_short_price_list) - series_1_real_test[index]) * cumulative_trading_qty\n",
    "            current_revenue = long_profit + short_profit\n",
    "            peak_loss = min(peak_loss, current_revenue)\n",
    "        \n",
    "        # Calculate the returns when exiting the market\n",
    "        if enter_market_signal and check_differnet_signal(value, last_value):\n",
    "            trade_oppotunities += 1\n",
    "            exiting_profit = current_revenue - INVESTIBLE_CAPITAL_EACH_TIME * count_entering_time * TRADING_FEE_RATE # revenue for all symbols\n",
    "            \n",
    "            # Cumulate the return\n",
    "            cumulative_return += exiting_profit\n",
    "            return trade_oppotunities, cumulative_return, peak_loss\n",
    "        \n",
    "        last_value = value\n",
    "    \n",
    "    return trade_oppotunities, cumulative_return, peak_loss\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cointegrated_pairs(prices, interval, trainning_period, z_score_window, z_score_threshod) -> str:\n",
    "\n",
    "    # Loop through coins and check for co-integration\n",
    "    coint_pair_list = []\n",
    "    \n",
    "    found_pair_list = list(prices.keys())\n",
    "    loop_count = 0\n",
    "    for sym_1 in found_pair_list:\n",
    "        loop_count += 1\n",
    "        # Check each coin against the first (sym_1)\n",
    "        for sym_2 in found_pair_list[loop_count:]:\n",
    "            \n",
    "            # Get close prices\n",
    "            series_1 = prices[sym_1]\n",
    "            series_2 = prices[sym_2]\n",
    "            \n",
    "            # Get recent NUM_LIMITS prices.\n",
    "            series_1_coint_test = prices[sym_1][1499 - 50 - (trainning_period):1499 - 50]\n",
    "            series_2_coint_test = prices[sym_2][1499 - 50 - (trainning_period):1499 - 50]\n",
    "\n",
    "            # Check for cointegration and add cointegrated pair\n",
    "            coint_flag, p_value, hedge_ratio, initial_intercept = calculate_cointegration_static(series_1_coint_test, series_2_coint_test)\n",
    "            \n",
    "\n",
    "            \n",
    "            if (coint_flag == 1) and (hedge_ratio > 0.01) and (hedge_ratio < 100):\n",
    "                series_1_train_test = prices[sym_1][1499 - 50 - (trainning_period + 2 * z_score_window):1499 - 50]\n",
    "                series_2_train_test = prices[sym_2][1499 - 50 - (trainning_period + 2 * z_score_window):1499 - 50]\n",
    "                \n",
    "                series_1_real_test = prices[sym_1][1499 - (2 * z_score_window):]\n",
    "                series_2_real_test = prices[sym_2][1499 - (2 * z_score_window):]\n",
    "                trade_oppotunities, cumulative_returns, win_rate, recent_trade_qty, recent_z_score, peak_loss, std = calculate_pairs_trading_result(series_1_train_test,\n",
    "                                                                                                                                              series_2_train_test,\n",
    "                                                                                                                                              z_score_window,\n",
    "                                                                                                                                              z_score_threshod)\n",
    "                one_time_trade_oppotunities, one_time_returns, one_time_peak_loss = calculate_pairs_one_time_trading_result(series_1_real_test, series_2_real_test, z_score_window, z_score_threshod)\n",
    "                \n",
    "                coint_pair_list.append({\n",
    "                    \"sym_1\": sym_1,\n",
    "                    \"sym_2\": sym_2,\n",
    "                    \"std\":std,\n",
    "                    \"p_value\": p_value,\n",
    "                    \"hedge_ratio\": hedge_ratio,\n",
    "                    \"initial_intercept\": initial_intercept,\n",
    "                    \"trading_oppotunities\": trade_oppotunities,\n",
    "                    \"estimated_returns\": cumulative_returns,\n",
    "                    \"win_rate\": win_rate,\n",
    "                    \"recent_trade_qty\": recent_trade_qty,\n",
    "                    \"peak_loss\": peak_loss,\n",
    "                    \"recent_z_score\": recent_z_score,\n",
    "                    \"one_time_trade_oppotunities\": one_time_trade_oppotunities,\n",
    "                    \"one_time_returns\": one_time_returns,\n",
    "                    \"one_time_peak_loss\": one_time_peak_loss,\n",
    "                })\n",
    "\n",
    "    # Output results and rank all the trading pairs\n",
    "    df_coint = pd.DataFrame(coint_pair_list)\n",
    "    # add the total score column\n",
    "    df_coint = df_coint.sort_values(\"estimated_returns\", ascending=False)\n",
    "    filename = f\"{interval}_{trainning_period}_{z_score_window}_{z_score_threshod}_cointegrated_pairs.csv\"\n",
    "    # choose positive hedge ratio\n",
    "    df_coint = df_coint[df_coint[\"hedge_ratio\"] > 0]\n",
    "    df_coint.to_csv(filename)\n",
    "    \n",
    "    print(f\"{interval}_{trainning_period}_{z_score_window}_cointegrated_pairs.csv has been completed\")\n",
    "    return df_coint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1m_100_20_cointegrated_pairs.csv has been completed\n",
      "1m_100_20_cointegrated_pairs.csv has been completed\n",
      "1m_100_20_cointegrated_pairs.csv has been completed\n",
      "1m_100_20_cointegrated_pairs.csv has been completed\n",
      "1m_100_20_cointegrated_pairs.csv has been completed\n",
      "1m_100_20_cointegrated_pairs.csv has been completed\n",
      "1m_100_20_cointegrated_pairs.csv has been completed\n",
      "1m_100_40_cointegrated_pairs.csv has been completed\n",
      "1m_100_40_cointegrated_pairs.csv has been completed\n",
      "1m_100_40_cointegrated_pairs.csv has been completed\n",
      "1m_100_40_cointegrated_pairs.csv has been completed\n",
      "1m_100_40_cointegrated_pairs.csv has been completed\n",
      "1m_100_40_cointegrated_pairs.csv has been completed\n",
      "1m_100_40_cointegrated_pairs.csv has been completed\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[102], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[39mfor\u001b[39;00m z_score_window \u001b[39min\u001b[39;00m SET_Z_SCORE_WINDOW:\n\u001b[1;32m     21\u001b[0m     \u001b[39mfor\u001b[39;00m z_score_threshod \u001b[39min\u001b[39;00m SET_TRIGGER_Z_SCORE_THRESHOD:\n\u001b[0;32m---> 22\u001b[0m         df_coint \u001b[39m=\u001b[39m test_parameters(interval, trainning_period, z_score_window, z_score_threshod)\n\u001b[1;32m     23\u001b[0m         average_return, win_rate \u001b[39m=\u001b[39m get_trainning_result(df_coint)\n\u001b[1;32m     24\u001b[0m         temp_dict \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39minterval\u001b[39m\u001b[39m\"\u001b[39m:interval, \u001b[39m\"\u001b[39m\u001b[39mtrainning_period\u001b[39m\u001b[39m\"\u001b[39m: trainning_period, \u001b[39m\"\u001b[39m\u001b[39mz_score_window\u001b[39m\u001b[39m\"\u001b[39m: z_score_window,\n\u001b[1;32m     25\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39mz_score_threshod\u001b[39m\u001b[39m\"\u001b[39m: z_score_threshod, \u001b[39m\"\u001b[39m\u001b[39mtest_average_returns\u001b[39m\u001b[39m\"\u001b[39m: average_return, \u001b[39m\"\u001b[39m\u001b[39mtest_win_rate\u001b[39m\u001b[39m\"\u001b[39m:win_rate}\n",
      "Cell \u001b[0;32mIn[102], line 5\u001b[0m, in \u001b[0;36mtest_parameters\u001b[0;34m(interval, trainning_period, z_score_window, z_score_threshod)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m (\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00minterval\u001b[39m}\u001b[39;00m\u001b[39m_price_list.json\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m json_file:\n\u001b[1;32m      4\u001b[0m     price_data \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mload(json_file)\n\u001b[0;32m----> 5\u001b[0m     df_coint \u001b[39m=\u001b[39m get_cointegrated_pairs(price_data, interval, trainning_period, z_score_window, z_score_threshod)\n\u001b[1;32m      6\u001b[0m     \u001b[39mreturn\u001b[39;00m df_coint\n",
      "Cell \u001b[0;32mIn[100], line 22\u001b[0m, in \u001b[0;36mget_cointegrated_pairs\u001b[0;34m(prices, interval, trainning_period, z_score_window, z_score_threshod)\u001b[0m\n\u001b[1;32m     19\u001b[0m series_2_coint_test \u001b[39m=\u001b[39m prices[sym_2][\u001b[39m1499\u001b[39m \u001b[39m-\u001b[39m \u001b[39m50\u001b[39m \u001b[39m-\u001b[39m (trainning_period):\u001b[39m1499\u001b[39m \u001b[39m-\u001b[39m \u001b[39m50\u001b[39m]\n\u001b[1;32m     21\u001b[0m \u001b[39m# Check for cointegration and add cointegrated pair\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m coint_flag, p_value, hedge_ratio, initial_intercept \u001b[39m=\u001b[39m calculate_cointegration_static(series_1_coint_test, series_2_coint_test)\n\u001b[1;32m     26\u001b[0m \u001b[39mif\u001b[39;00m (coint_flag \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m) \u001b[39mand\u001b[39;00m (hedge_ratio \u001b[39m>\u001b[39m \u001b[39m0.01\u001b[39m) \u001b[39mand\u001b[39;00m (hedge_ratio \u001b[39m<\u001b[39m \u001b[39m100\u001b[39m):\n\u001b[1;32m     27\u001b[0m     series_1_train_test \u001b[39m=\u001b[39m prices[sym_1][\u001b[39m1499\u001b[39m \u001b[39m-\u001b[39m \u001b[39m50\u001b[39m \u001b[39m-\u001b[39m (trainning_period \u001b[39m+\u001b[39m \u001b[39m2\u001b[39m \u001b[39m*\u001b[39m z_score_window):\u001b[39m1499\u001b[39m \u001b[39m-\u001b[39m \u001b[39m50\u001b[39m]\n",
      "Cell \u001b[0;32mIn[96], line 32\u001b[0m, in \u001b[0;36mcalculate_cointegration_static\u001b[0;34m(series_1, series_2)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[39mCalculate the cointegration between two series and return cointegration flag,\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[39mhedge ratio, and initial intercept.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     28\u001b[0m \n\u001b[1;32m     29\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     31\u001b[0m coint_flag \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m---> 32\u001b[0m coint_res \u001b[39m=\u001b[39m coint(series_1, series_2)\n\u001b[1;32m     33\u001b[0m coint_t \u001b[39m=\u001b[39m coint_res[\u001b[39m0\u001b[39m]\n\u001b[1;32m     34\u001b[0m p_value \u001b[39m=\u001b[39m coint_res[\u001b[39m1\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/Pybit-trade/lib/python3.11/site-packages/statsmodels/tsa/stattools.py:1717\u001b[0m, in \u001b[0;36mcoint\u001b[0;34m(y0, y1, trend, method, maxlag, autolag, return_results)\u001b[0m\n\u001b[1;32m   1714\u001b[0m res_co \u001b[39m=\u001b[39m OLS(y0, xx)\u001b[39m.\u001b[39mfit()\n\u001b[1;32m   1716\u001b[0m \u001b[39mif\u001b[39;00m res_co\u001b[39m.\u001b[39mrsquared \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m \u001b[39m-\u001b[39m \u001b[39m100\u001b[39m \u001b[39m*\u001b[39m SQRTEPS:\n\u001b[0;32m-> 1717\u001b[0m     res_adf \u001b[39m=\u001b[39m adfuller(\n\u001b[1;32m   1718\u001b[0m         res_co\u001b[39m.\u001b[39;49mresid, maxlag\u001b[39m=\u001b[39;49mmaxlag, autolag\u001b[39m=\u001b[39;49mautolag, regression\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mn\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m   1719\u001b[0m     )\n\u001b[1;32m   1720\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1721\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   1722\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39my0 and y1 are (almost) perfectly colinear.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1723\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCointegration test is not reliable in this case.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1724\u001b[0m         CollinearityWarning,\n\u001b[1;32m   1725\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/Pybit-trade/lib/python3.11/site-packages/statsmodels/tsa/stattools.py:321\u001b[0m, in \u001b[0;36madfuller\u001b[0;34m(x, maxlag, regression, autolag, store, regresults)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[39m# 1 for level\u001b[39;00m\n\u001b[1;32m    316\u001b[0m \u001b[39m# search for lag length with smallest information criteria\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[39m# Note: use the same number of observations to have comparable IC\u001b[39;00m\n\u001b[1;32m    318\u001b[0m \u001b[39m# aic and bic: smaller is better\u001b[39;00m\n\u001b[1;32m    320\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m regresults:\n\u001b[0;32m--> 321\u001b[0m     icbest, bestlag \u001b[39m=\u001b[39m _autolag(\n\u001b[1;32m    322\u001b[0m         OLS, xdshort, fullRHS, startlag, maxlag, autolag\n\u001b[1;32m    323\u001b[0m     )\n\u001b[1;32m    324\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    325\u001b[0m     icbest, bestlag, alres \u001b[39m=\u001b[39m _autolag(\n\u001b[1;32m    326\u001b[0m         OLS,\n\u001b[1;32m    327\u001b[0m         xdshort,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    332\u001b[0m         regresults\u001b[39m=\u001b[39mregresults,\n\u001b[1;32m    333\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/Pybit-trade/lib/python3.11/site-packages/statsmodels/tsa/stattools.py:129\u001b[0m, in \u001b[0;36m_autolag\u001b[0;34m(mod, endog, exog, startlag, maxlag, method, modargs, fitargs, regresults)\u001b[0m\n\u001b[1;32m    127\u001b[0m method \u001b[39m=\u001b[39m method\u001b[39m.\u001b[39mlower()\n\u001b[1;32m    128\u001b[0m \u001b[39mfor\u001b[39;00m lag \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(startlag, startlag \u001b[39m+\u001b[39m maxlag \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[0;32m--> 129\u001b[0m     mod_instance \u001b[39m=\u001b[39m mod(endog, exog[:, :lag], \u001b[39m*\u001b[39;49mmodargs)\n\u001b[1;32m    130\u001b[0m     results[lag] \u001b[39m=\u001b[39m mod_instance\u001b[39m.\u001b[39mfit()\n\u001b[1;32m    132\u001b[0m \u001b[39mif\u001b[39;00m method \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39maic\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/Pybit-trade/lib/python3.11/site-packages/statsmodels/regression/linear_model.py:906\u001b[0m, in \u001b[0;36mOLS.__init__\u001b[0;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[1;32m    903\u001b[0m     msg \u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39mWeights are not supported in OLS and will be ignored\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    904\u001b[0m            \u001b[39m\"\u001b[39m\u001b[39mAn exception will be raised in the next version.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    905\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(msg, ValueWarning)\n\u001b[0;32m--> 906\u001b[0m \u001b[39msuper\u001b[39;49m(OLS, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(endog, exog, missing\u001b[39m=\u001b[39;49mmissing,\n\u001b[1;32m    907\u001b[0m                           hasconst\u001b[39m=\u001b[39;49mhasconst, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    908\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mweights\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_keys:\n\u001b[1;32m    909\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_keys\u001b[39m.\u001b[39mremove(\u001b[39m\"\u001b[39m\u001b[39mweights\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/Pybit-trade/lib/python3.11/site-packages/statsmodels/regression/linear_model.py:733\u001b[0m, in \u001b[0;36mWLS.__init__\u001b[0;34m(self, endog, exog, weights, missing, hasconst, **kwargs)\u001b[0m\n\u001b[1;32m    731\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    732\u001b[0m     weights \u001b[39m=\u001b[39m weights\u001b[39m.\u001b[39msqueeze()\n\u001b[0;32m--> 733\u001b[0m \u001b[39msuper\u001b[39;49m(WLS, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(endog, exog, missing\u001b[39m=\u001b[39;49mmissing,\n\u001b[1;32m    734\u001b[0m                           weights\u001b[39m=\u001b[39;49mweights, hasconst\u001b[39m=\u001b[39;49mhasconst, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    735\u001b[0m nobs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexog\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[1;32m    736\u001b[0m weights \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights\n",
      "File \u001b[0;32m~/anaconda3/envs/Pybit-trade/lib/python3.11/site-packages/statsmodels/regression/linear_model.py:190\u001b[0m, in \u001b[0;36mRegressionModel.__init__\u001b[0;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, endog, exog, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 190\u001b[0m     \u001b[39msuper\u001b[39;49m(RegressionModel, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(endog, exog, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    191\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_attr\u001b[39m.\u001b[39mextend([\u001b[39m'\u001b[39m\u001b[39mpinv_wexog\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mwendog\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mwexog\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mweights\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/Pybit-trade/lib/python3.11/site-packages/statsmodels/base/model.py:267\u001b[0m, in \u001b[0;36mLikelihoodModel.__init__\u001b[0;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, endog, exog\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 267\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(endog, exog, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    268\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minitialize()\n",
      "File \u001b[0;32m~/anaconda3/envs/Pybit-trade/lib/python3.11/site-packages/statsmodels/base/model.py:92\u001b[0m, in \u001b[0;36mModel.__init__\u001b[0;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m missing \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m'\u001b[39m\u001b[39mmissing\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mnone\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     91\u001b[0m hasconst \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m'\u001b[39m\u001b[39mhasconst\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m---> 92\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_handle_data(endog, exog, missing, hasconst,\n\u001b[1;32m     93\u001b[0m                               \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     94\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mk_constant \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mk_constant\n\u001b[1;32m     95\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexog \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mexog\n",
      "File \u001b[0;32m~/anaconda3/envs/Pybit-trade/lib/python3.11/site-packages/statsmodels/base/model.py:132\u001b[0m, in \u001b[0;36mModel._handle_data\u001b[0;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_handle_data\u001b[39m(\u001b[39mself\u001b[39m, endog, exog, missing, hasconst, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 132\u001b[0m     data \u001b[39m=\u001b[39m handle_data(endog, exog, missing, hasconst, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    133\u001b[0m     \u001b[39m# kwargs arrays could have changed, easier to just attach here\u001b[39;00m\n\u001b[1;32m    134\u001b[0m     \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m kwargs:\n",
      "File \u001b[0;32m~/anaconda3/envs/Pybit-trade/lib/python3.11/site-packages/statsmodels/base/data.py:700\u001b[0m, in \u001b[0;36mhandle_data\u001b[0;34m(endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[1;32m    697\u001b[0m     exog \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(exog)\n\u001b[1;32m    699\u001b[0m klass \u001b[39m=\u001b[39m handle_data_class_factory(endog, exog)\n\u001b[0;32m--> 700\u001b[0m \u001b[39mreturn\u001b[39;00m klass(endog, exog\u001b[39m=\u001b[39;49mexog, missing\u001b[39m=\u001b[39;49mmissing, hasconst\u001b[39m=\u001b[39;49mhasconst,\n\u001b[1;32m    701\u001b[0m              \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/Pybit-trade/lib/python3.11/site-packages/statsmodels/base/data.py:88\u001b[0m, in \u001b[0;36mModelData.__init__\u001b[0;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconst_idx \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mk_constant \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m---> 88\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_handle_constant(hasconst)\n\u001b[1;32m     89\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_integrity()\n\u001b[1;32m     90\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cache \u001b[39m=\u001b[39m {}\n",
      "File \u001b[0;32m~/anaconda3/envs/Pybit-trade/lib/python3.11/site-packages/statsmodels/base/data.py:177\u001b[0m, in \u001b[0;36mModelData._handle_constant\u001b[0;34m(self, hasconst)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[39mif\u001b[39;00m check_implicit \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m hasconst:\n\u001b[1;32m    173\u001b[0m     \u001b[39m# look for implicit constant\u001b[39;00m\n\u001b[1;32m    174\u001b[0m     \u001b[39m# Compute rank of augmented matrix\u001b[39;00m\n\u001b[1;32m    175\u001b[0m     augmented_exog \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mcolumn_stack(\n\u001b[1;32m    176\u001b[0m                 (np\u001b[39m.\u001b[39mones(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexog\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexog))\n\u001b[0;32m--> 177\u001b[0m     rank_augm \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mlinalg\u001b[39m.\u001b[39;49mmatrix_rank(augmented_exog)\n\u001b[1;32m    178\u001b[0m     rank_orig \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39mmatrix_rank(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexog)\n\u001b[1;32m    179\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mk_constant \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(rank_orig \u001b[39m==\u001b[39m rank_augm)\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mmatrix_rank\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/Pybit-trade/lib/python3.11/site-packages/numpy/linalg/linalg.py:1888\u001b[0m, in \u001b[0;36mmatrix_rank\u001b[0;34m(A, tol, hermitian)\u001b[0m\n\u001b[1;32m   1886\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1887\u001b[0m     tol \u001b[39m=\u001b[39m asarray(tol)[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, newaxis]\n\u001b[0;32m-> 1888\u001b[0m \u001b[39mreturn\u001b[39;00m count_nonzero(S \u001b[39m>\u001b[39;49m tol, axis\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[0;32m<__array_function__ internals>:177\u001b[0m, in \u001b[0;36mcount_nonzero\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "def test_parameters(interval, trainning_period, z_score_window, z_score_threshod):\n",
    "    with open (f\"{interval}_price_list.json\") as json_file:\n",
    "        price_data = json.load(json_file)\n",
    "        df_coint = get_cointegrated_pairs(price_data, interval, trainning_period, z_score_window, z_score_threshod)\n",
    "        return df_coint\n",
    "\n",
    "def get_trainning_result(df_coint: pd.DataFrame):\n",
    "    df_coint = df_coint[df_coint[\"estimated_returns\"] > 0].head(10)\n",
    "    df_coint = df_coint[abs(df_coint[\"peak_loss\"]) < 0.2 * INVESTIBLE_CAPITAL_EACH_TIME]\n",
    "    average_return = df_coint[\"one_time_returns\"].mean()\n",
    "    average_loss = df_coint[df_coint[\"one_time_returns\"] < 0].mean()\n",
    "    if df_coint.shape[0] != 0:\n",
    "        win_rate = (df_coint[df_coint[\"one_time_returns\"] > 0].shape[0] / df_coint.shape[0])\n",
    "    else: win_rate = 0\n",
    "    return average_return, win_rate, average_loss\n",
    "\n",
    "result_list = []\n",
    "for interval in SET_INTERVALS:\n",
    "    for trainning_period in SET_TRAINNING_PERIODS:\n",
    "        for z_score_window in SET_Z_SCORE_WINDOW:\n",
    "            for z_score_threshod in SET_TRIGGER_Z_SCORE_THRESHOD:\n",
    "                df_coint = test_parameters(interval, trainning_period, z_score_window, z_score_threshod)\n",
    "                average_return, win_rate, average_loss = get_trainning_result(df_coint)\n",
    "                temp_dict = {\"interval\":interval, \"trainning_period\": trainning_period, \"z_score_window\": z_score_window,\n",
    "                             \"z_score_threshod\": z_score_threshod, \"test_average_returns\": average_return, \"test_win_rate\":win_rate,\n",
    "                             \"test_ave_loss\": average_loss}\n",
    "                result_list.append(temp_dict)\n",
    "                df_result = pd.DataFrame(result_list)\n",
    "                df_result.to_csv(\"analysis.csv\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sym_1</th>\n",
       "      <th>sym_2</th>\n",
       "      <th>std</th>\n",
       "      <th>p_value</th>\n",
       "      <th>hedge_ratio</th>\n",
       "      <th>initial_intercept</th>\n",
       "      <th>trading_oppotunities</th>\n",
       "      <th>estimated_returns</th>\n",
       "      <th>win_rate</th>\n",
       "      <th>recent_trade_qty</th>\n",
       "      <th>peak_loss</th>\n",
       "      <th>recent_z_score</th>\n",
       "      <th>one_time_trade_oppotunities</th>\n",
       "      <th>one_time_returns</th>\n",
       "      <th>one_time_peak_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>BCHUSDT</td>\n",
       "      <td>TOMOUSDT</td>\n",
       "      <td>104.340193</td>\n",
       "      <td>0.010185</td>\n",
       "      <td>51.366389</td>\n",
       "      <td>182.865998</td>\n",
       "      <td>9</td>\n",
       "      <td>1887.543322</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.253064</td>\n",
       "      <td>-79.806720</td>\n",
       "      <td>1.856927</td>\n",
       "      <td>1</td>\n",
       "      <td>80.603238</td>\n",
       "      <td>-4.961395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>UNIUSDT</td>\n",
       "      <td>ZENUSDT</td>\n",
       "      <td>4.413268</td>\n",
       "      <td>0.018671</td>\n",
       "      <td>0.621808</td>\n",
       "      <td>0.924200</td>\n",
       "      <td>13</td>\n",
       "      <td>1018.273771</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>213.444731</td>\n",
       "      <td>-172.818079</td>\n",
       "      <td>1.421342</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-42.001261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>FTMUSDT</td>\n",
       "      <td>TOMOUSDT</td>\n",
       "      <td>0.100835</td>\n",
       "      <td>0.003658</td>\n",
       "      <td>0.014392</td>\n",
       "      <td>0.240290</td>\n",
       "      <td>13</td>\n",
       "      <td>351.084517</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>1098.985883</td>\n",
       "      <td>-95.107838</td>\n",
       "      <td>1.726565</td>\n",
       "      <td>1</td>\n",
       "      <td>111.748745</td>\n",
       "      <td>-12.622201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>FTMUSDT</td>\n",
       "      <td>STMXUSDT</td>\n",
       "      <td>0.110142</td>\n",
       "      <td>0.004504</td>\n",
       "      <td>0.089314</td>\n",
       "      <td>0.257195</td>\n",
       "      <td>9</td>\n",
       "      <td>259.974118</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>839.457725</td>\n",
       "      <td>-84.344562</td>\n",
       "      <td>2.595934</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-13.631452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>ATOMUSDT</td>\n",
       "      <td>UNIUSDT</td>\n",
       "      <td>3.909655</td>\n",
       "      <td>0.006055</td>\n",
       "      <td>0.706606</td>\n",
       "      <td>5.082743</td>\n",
       "      <td>10</td>\n",
       "      <td>230.346460</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>9.018283</td>\n",
       "      <td>-30.655257</td>\n",
       "      <td>-0.776951</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.481637</td>\n",
       "      <td>-2.081637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BCHUSDT</td>\n",
       "      <td>DOTUSDT</td>\n",
       "      <td>141.891255</td>\n",
       "      <td>0.004130</td>\n",
       "      <td>4.897000</td>\n",
       "      <td>218.770642</td>\n",
       "      <td>14</td>\n",
       "      <td>-905.109945</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.535716</td>\n",
       "      <td>-830.511636</td>\n",
       "      <td>-1.157035</td>\n",
       "      <td>1</td>\n",
       "      <td>4.647558</td>\n",
       "      <td>-1.693321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>BCHUSDT</td>\n",
       "      <td>CRVUSDT</td>\n",
       "      <td>144.989465</td>\n",
       "      <td>0.002170</td>\n",
       "      <td>44.925334</td>\n",
       "      <td>209.724091</td>\n",
       "      <td>10</td>\n",
       "      <td>-1038.578465</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.451044</td>\n",
       "      <td>-1095.048741</td>\n",
       "      <td>-0.237127</td>\n",
       "      <td>1</td>\n",
       "      <td>8.235363</td>\n",
       "      <td>-0.559301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>TRXUSDT</td>\n",
       "      <td>WAVESUSDT</td>\n",
       "      <td>0.038730</td>\n",
       "      <td>0.000820</td>\n",
       "      <td>0.044902</td>\n",
       "      <td>-0.007130</td>\n",
       "      <td>12</td>\n",
       "      <td>-1221.128233</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>520567.802487</td>\n",
       "      <td>-1122.239495</td>\n",
       "      <td>0.785689</td>\n",
       "      <td>1</td>\n",
       "      <td>102.121616</td>\n",
       "      <td>-2.073345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BCHUSDT</td>\n",
       "      <td>BNBUSDT</td>\n",
       "      <td>200.435066</td>\n",
       "      <td>0.003888</td>\n",
       "      <td>1.024481</td>\n",
       "      <td>-3.801153</td>\n",
       "      <td>13</td>\n",
       "      <td>-1459.640510</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.410590</td>\n",
       "      <td>-1329.713600</td>\n",
       "      <td>-0.293669</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-19.639932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>BCHUSDT</td>\n",
       "      <td>DYDXUSDT</td>\n",
       "      <td>116.794204</td>\n",
       "      <td>0.005807</td>\n",
       "      <td>12.900814</td>\n",
       "      <td>217.387001</td>\n",
       "      <td>10</td>\n",
       "      <td>-3771.436505</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.462892</td>\n",
       "      <td>-3785.097567</td>\n",
       "      <td>-0.633767</td>\n",
       "      <td>1</td>\n",
       "      <td>14.123523</td>\n",
       "      <td>-0.634013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82 rows  15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sym_1      sym_2         std   p_value  hedge_ratio  initial_intercept  \\\n",
       "14   BCHUSDT   TOMOUSDT  104.340193  0.010185    51.366389         182.865998   \n",
       "56   UNIUSDT    ZENUSDT    4.413268  0.018671     0.621808           0.924200   \n",
       "58   FTMUSDT   TOMOUSDT    0.100835  0.003658     0.014392           0.240290   \n",
       "63   FTMUSDT   STMXUSDT    0.110142  0.004504     0.089314           0.257195   \n",
       "45  ATOMUSDT    UNIUSDT    3.909655  0.006055     0.706606           5.082743   \n",
       "..       ...        ...         ...       ...          ...                ...   \n",
       "9    BCHUSDT    DOTUSDT  141.891255  0.004130     4.897000         218.770642   \n",
       "10   BCHUSDT    CRVUSDT  144.989465  0.002170    44.925334         209.724091   \n",
       "35   TRXUSDT  WAVESUSDT    0.038730  0.000820     0.044902          -0.007130   \n",
       "4    BCHUSDT    BNBUSDT  200.435066  0.003888     1.024481          -3.801153   \n",
       "22   BCHUSDT   DYDXUSDT  116.794204  0.005807    12.900814         217.387001   \n",
       "\n",
       "    trading_oppotunities  estimated_returns  win_rate  recent_trade_qty  \\\n",
       "14                     9        1887.543322  0.666667          1.253064   \n",
       "56                    13        1018.273771  0.384615        213.444731   \n",
       "58                    13         351.084517  0.615385       1098.985883   \n",
       "63                     9         259.974118  0.555556        839.457725   \n",
       "45                    10         230.346460  0.600000          9.018283   \n",
       "..                   ...                ...       ...               ...   \n",
       "9                     14        -905.109945  0.571429          0.535716   \n",
       "10                    10       -1038.578465  0.500000          0.451044   \n",
       "35                    12       -1221.128233  0.250000     520567.802487   \n",
       "4                     13       -1459.640510  0.384615          0.410590   \n",
       "22                    10       -3771.436505  0.400000          0.462892   \n",
       "\n",
       "      peak_loss  recent_z_score  one_time_trade_oppotunities  \\\n",
       "14   -79.806720        1.856927                            1   \n",
       "56  -172.818079        1.421342                            0   \n",
       "58   -95.107838        1.726565                            1   \n",
       "63   -84.344562        2.595934                            0   \n",
       "45   -30.655257       -0.776951                            1   \n",
       "..          ...             ...                          ...   \n",
       "9   -830.511636       -1.157035                            1   \n",
       "10 -1095.048741       -0.237127                            1   \n",
       "35 -1122.239495        0.785689                            1   \n",
       "4  -1329.713600       -0.293669                            0   \n",
       "22 -3785.097567       -0.633767                            1   \n",
       "\n",
       "    one_time_returns  one_time_peak_loss  \n",
       "14         80.603238           -4.961395  \n",
       "56          0.000000          -42.001261  \n",
       "58        111.748745          -12.622201  \n",
       "63          0.000000          -13.631452  \n",
       "45         -2.481637           -2.081637  \n",
       "..               ...                 ...  \n",
       "9           4.647558           -1.693321  \n",
       "10          8.235363           -0.559301  \n",
       "35        102.121616           -2.073345  \n",
       "4           0.000000          -19.639932  \n",
       "22         14.123523           -0.634013  \n",
       "\n",
       "[82 rows x 15 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df[df[\"estimated_returns\"] > 0].head(10)\n",
    "df2 = df1[abs(df1[\"peak_loss\"]) < 0.2 * INVESTIBLE_CAPITAL_EACH_TIME]\n",
    "df2[\"one_time_returns\"].mean()\n",
    "df2[df2[\"one_time_returns\"] > 0].shape[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pybit-trade",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
